{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101,)\n",
      "(101,)\n"
     ]
    }
   ],
   "source": [
    "trX = np.linspace(-1, 1, 101)\n",
    "trY = 2 * trX + np.random.randn(*trX.shape) * 0.33 # create a y value which is approximately linear but with some random noise\n",
    "print(trX.shape)\n",
    "print(trY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(\"float\") # create symbolic variables\n",
    "Y = tf.placeholder(\"float\")\n",
    "\n",
    "def model(X, w, b):\n",
    "    return tf.add(tf.multiply(X, w),b) # lr is just X*w so this model line is pretty simple\n",
    "\n",
    "w = tf.Variable(0.0, name=\"weights\") # create a shared variable (like theano.shared) for the weight matrix\n",
    "b = tf.Variable(0.0, name=\"biases\")\n",
    "y_model = model(X, w, b)\n",
    "\n",
    "cost = tf.square(Y - y_model) # use square error for cost function\n",
    "\n",
    "train_op = tf.train.GradientDescentOptimizer(0.01).minimize(cost) # construct an optimizer to minimize cost and fit line to my data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step  0 => w:  0.86165\t, b:  0.330458\t, cost:  0.964473\n",
      "Step  20 => w:  2.00641\t, b:  -0.0159244\t, cost:  0.0337462\n",
      "Step  40 => w:  2.00641\t, b:  -0.0159249\t, cost:  0.0337459\n",
      "Step  60 => w:  2.00641\t, b:  -0.0159249\t, cost:  0.0337459\n",
      "Step  80 => w:  2.00641\t, b:  -0.0159249\t, cost:  0.0337459\n",
      "\n",
      "result\n",
      "w: 2.00641 , b:  -0.0159249\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph in a session\n",
    "with tf.Session() as sess:\n",
    "    # you need to initialize variables (in this case just variable W)\n",
    "    tf.global_variables_initializer().run()\n",
    "    for i in range(100):\n",
    "        feeds = {X: x, Y: y}\n",
    "        for (x, y) in zip(trX, trY):\n",
    "            sess.run(train_op, feed_dict=feeds)\n",
    "        if i % 20 == 0:\n",
    "            print(\"Step \", i, \"=>\", end=\" \")\n",
    "            print(\"w: \", sess.run(w, feed_dict=feeds), end='\\t, ')\n",
    "            print(\"b: \", sess.run(b, feed_dict=feeds), end='\\t, ')\n",
    "            print(\"cost: \", sess.run(cost, feed_dict=feeds))\n",
    "    print(\"\\nresult\\nw:\", sess.run(w), \", b: \", sess.run(b))  # It should be something around 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
